{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8eaa06",
   "metadata": {},
   "source": [
    "# Proyecto Final Statistical Learning I: Parte 3\n",
    "\n",
    "Esta sección corresponde a la parte final del proyecto, en la que se incluyen un Ensayo sobre Support Vector Machine, una investigación sobre la técnica K-Fold Cross Validation y una investigación sobre métodos de deploy y export con TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4471fc6",
   "metadata": {},
   "source": [
    "## Ensayo SVM\n",
    "\n",
    "SVM se refiere al algoritmo Support Vector Machines muy útil en problemas de clasificación lineal y no lineal, también puede aplicarse a regresión y detección de outliers. SVM busca separar las clases por una frontera de decisión que se encuentre a la distancia máxima entre los puntos más cercanos de las clases. \n",
    "\n",
    "Por ejemplo, en la siguiente imagen puede observarse que la línea que mejor separa las clases y previene casos ambiguos es la línea roja para este caso en particular. Los puntos que definen el ancho del gap son llamados vectores de soporte o 'Support Vectors' (de ahí el nombre). El 'gap' es llamado también **margen grande de clasificación**.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/0*INqwwHXgTabQx7wM.png\" alt=\"alt text\" width=\"400\"/>\n",
    "<center> Créditos: Shubhang Agrawal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64696e91",
   "metadata": {},
   "source": [
    "### Hipótesis\n",
    "\n",
    "La hipótesis de SVM está relacionada a la de la regresión logística. \n",
    "\n",
    "$$h_Θ(x) = g(Θ^Tx) = \\frac{1}{1+e^{-Θ^Tx}} $$\n",
    "\n",
    "Si $y=1$, queremos que $h_Θ(x) ≈ 1$, o que $$Θ^Tx >> 0$$\n",
    "Si $y=0$, queremos que $h_Θ(x) ≈ 0$, o que $$Θ^Tx << 0$$\n",
    "\n",
    "La gran diferencia es que la regresión logística arroja resultados probabilísticos, mientras que la hipótesis de SVM solo indica 0 o 1.\n",
    "\n",
    "$$h_Θ(x) =\\left\\{\n",
    "    \\begin{array}{lr}\n",
    "    1 \\text{ si } Θ^Tx >= 0\\\\\n",
    "    0 \\text{ en } otros puntos\\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "652eb109",
   "metadata": {},
   "source": [
    "### Función de costo\n",
    "\n",
    "La función de costo es:\n",
    "<img src=\"https://www.freecodecamp.org/news/content/images/2020/02/SOhv2jZ.png\" alt=\"alt text\" width=\"400\"/>\n",
    "\n",
    "Y en realidad es muy similar a la función de costo de regresión logística. La gran diferencia está en la pendiente de las curvas:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/alexeygrigorev/wiki-figures/master/legacy/svm-vs-lr-cost.png\" alt=\"alt text\" width=\"400\"/>\n",
    "<center> Créditos: Alexey Grigorev\n",
    "    \n",
    "La función de costo se usa para entrenar el modelo. El objetivo, como siempre, es minimizar el costo. En la ecuación cost1 y cost0 se refieren al costo donde y=1 y al costo donde y=0 en cierto ejemplo específico. ***C*** es un parámetro de regularización (hyper-parameter) y es equivalente al inverso de lambda.      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b94e43",
   "metadata": {},
   "source": [
    "### Ventas y desventajas\n",
    "\n",
    "**Ventajas**\n",
    "* SVM funciona relativamente bien cuando existe un claro margen de separación entre clases.\n",
    "* Es efectivo cuando el número de dimensiones es mayor que el número de muestras.\n",
    "* Es relativamente eficiente en términos de uso de memoria.\n",
    "\n",
    "**Desventajas**\n",
    "* No es adecuado para datasets demasiado grandes.\n",
    "* En los casos donde existe ruido o las clases se traslapan, SVM no tiene buen rendimiento.\n",
    "* Si el número de features de cada observación excede el número de muestras de entrenamiento, SVM tampoco tiene buen rendimiento. \n",
    "* El modelo no tiene mucha explicabilidad ya que funciona por colocar puntos arriba y debajo del hiperplano de clasificación. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8cf96d",
   "metadata": {},
   "source": [
    "### Kernel Trick\n",
    "\n",
    "Cuando los datos no son linealmente separables se hace necesario aplicar transformaciones a las features de manerea que sean linealmente separables, normalmente estas transformaciones llevan los datos a dimensiones más altas en las cuales si son separables. El problema es que muchas veces, este incremento dimensional implica combinaciones polinomiales y de otro tipo que son imprácticos y computacionalmente ineficientes. Para resolver este problema, se utiliza el kernel trick.\n",
    "\n",
    "Este truco consiste en aplicar una función kernel, la cual tiene una propiedad especial para entrenar los vectores de soporte. El truco se basa en representar los datos a través de un conjunto de comparaciones de de pares de observaciones, sin aplicar las transformaciones y luego representar las coordenadas transformadas en las dimensiones superiores.En términos simples la función kernel es un producto punto modificado. \n",
    "\n",
    "Algunos kernels comunes son:\n",
    "* Kernel Polinomial: se utiliza mucho en procesamiento de imágenes.\n",
    "* Kernel Gaussiano: se utiliza en aplicaciones de uso general.\n",
    "* Kernel RBF: Radial Basis Function, también para aplicaciones de uso general.\n",
    "* Kernel RBF Laplace: se utiliza en aplicaciones de uso general.\n",
    "* Kernel de Tangente Hiperbólica: se usa en redes neuronales.\n",
    "* Kernel Sigmoid: se utiliza como un \"proxy\" en redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45de9f",
   "metadata": {},
   "source": [
    "Un ejemplo de implementación de SVM usando sci-kit learn puede ser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "399974ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# Exploramos los datos\n",
    "print(cancer.feature_names)\n",
    "print(cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f99ba3c",
   "metadata": {},
   "source": [
    "En este data set se proveen muchas características de un tumor y las variables target son dos: si es maligno o benigno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9640a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2,random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c97c3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# generamos el modelo svm con un kernel lineal\n",
    "clf = svm.SVC(C = 0.5, kernel='linear')\n",
    "\n",
    "# lo entrenamos con los datos de entrenamiento\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# realizamos una prediccion\n",
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15648671",
   "metadata": {},
   "source": [
    "La función svm.SVC permite ingresar como parámetro el valor de C (el inverso del parámetro de regularización), el kernel y otros parámetros que varían en función del kernel utilizado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64ceb420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efaef8",
   "metadata": {},
   "source": [
    "Luego de haber entrenado y hecho las predicciones, podemos medir el accuracy del modelo para ver que tan exacto es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e9b8d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.85964912280701\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_hat)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ec50b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffe176",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13c85a",
   "metadata": {},
   "source": [
    "Validación cruzada K-Fold es un método estadístico para medir el performance de un modelo. La idea principal de K-fold consiste en utilizar diferentes subsets para el entrenamiento del modelo y diferentes subsets para la validación, calculando la métrica de performance en cada \"fold\" para finalmente calcular la métrica promedio sobre los k-folds realizados. \n",
    "\n",
    "<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F4788946%2F82b5a41b6693a313b246f02d79e972d5%2FK%20FOLD.png?generation=1608195745131795&alt=media\" alt=\"alt text\" width=\"500\"/>\n",
    "<center> Créditos: Yash Khandelwal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0763f6",
   "metadata": {},
   "source": [
    "Compo se observa en la imagen, se realizan 5 folds y en cada fold se utilizan ciertos subsets para el entrenamiento y ciertos subsets (en menor proporción) para la validación. La métrica de performance (error, accuracy, etc.) se calcula en cada fold y finalmente, la métrica de performance general es el promedio de los performance en cada fold. \n",
    "\n",
    "Los pasos a seguir para aplicar k-fold cross validation son:\n",
    "\n",
    "* Mezclar de forma aleatoria el dataset.\n",
    "* Dividirlo en k secciones. \n",
    "* Para cada sección k: \n",
    " + Tomar un grupo como dataset de pruebas.\n",
    " + Tomar el resto de datos como dataset de entrenamiento.\n",
    "* Entrenar el modelo con los grupos de entrenamiento y evaluarlo en los grupos de prueba.\n",
    "* Retener la métrica de evaluación y descargar el modelo de cada k sección.\n",
    "* Resumir la métrica de performance con promedio. \n",
    "* Probar el modelo de nuevo en todos los datos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ea9ab",
   "metadata": {},
   "source": [
    "### Aplicación en el proyecto\n",
    "\n",
    "Para el proyecto k-fold cross validation podría implementarse utilizando **cross_val_score** de scikit learn en el caso de los modelos de sklearn. \n",
    "\n",
    "Esta función tiene varios parámetros pero los básicos son, estimator en que se define el modelo a validar, X que se refiere a las features, y son los datos de salida y cv que se refiere al método de validación cruzada, en el caso de ser None se crean por default 5 folds. En el siguiente ejemplo se muestra como podría aplicarse en el proyecto en el caso del modelo SVM:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe17a0a1",
   "metadata": {},
   "source": [
    ">>> from sklearn.model_selection import cross_val_score\n",
    ">>> SVM_model = svm.SVC(C=1.0, kernel='linear')\n",
    ">>> scores = cross_val_score(clf, X, y, cv=5)\n",
    ">>> scores\n",
    "array([0.96..., 1. , 0.96..., 0.96..., 1. ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d18bc",
   "metadata": {},
   "source": [
    "El siguiente paso consistiría en calcular el promedio de scores para tener la métrica final del modelo. En código equivaldría a hacer lo siguiente:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6119044",
   "metadata": {},
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9e82f",
   "metadata": {},
   "source": [
    "El parámetro de evaluación o de performance puede modificarse de acuerdo a las métricas disponibles entre ellas: f1, accuracy, mse, recall, precision, etc.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e81a681",
   "metadata": {},
   "source": [
    "## Métodos de deploy y export en TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103f8f4e",
   "metadata": {},
   "source": [
    "Los métodos de export y deploy en TensorFlow tienen como objetivo desplegar modelos ya entrenados y listos para utilizarse en nuevos ambientes. En el caso del proyecto, la idea es simular cómo se puede desplegar el modelo de regresión logística realizado en TensorFlow en un Jupyter notebook nuevo.\n",
    "\n",
    "El proceso puede resumirse en los siguientes pasos:\n",
    "* Crear una función\n",
    "* Exportarla a un archivo py (como un módulo de Python)\n",
    "* Invocarla en un nuevo notebook donde se desea implementar\n",
    "\n",
    "TensorFlow tiene su propio sistema de despliege llamado **TensorFlow Serving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar el modelo\n",
    "model.save('my_model/1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar y cargar el modelo\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# se indica el path o directorio de donde está el modelo a cargar\n",
    "loaded_model = load_model('my_model/1/')\n",
    "\n",
    "# el modelo puede utilizarse para predecir nuevos datos\n",
    "loaded_model.predict(test_images[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01343014",
   "metadata": {},
   "source": [
    "# Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca63d6",
   "metadata": {},
   "source": [
    "Agrawal, S. (2021, January 20). Introduction to Support Vector Machine(SVM) - Artificial Intelligence in Plain English. Medium. https://ai.plainenglish.io/introduction-to-support-vector-machine-svm-cd0759098471\n",
    "\n",
    "freeCodeCamp.org. (2021, April 28). SVM Machine Learning Algorithm Explained. https://www.freecodecamp.org/news/support-vector-machines/\n",
    "\n",
    "sklearn.svm.SVC — scikit-learn 0.24.2 documentation. (n.d.). Scikit-Learn. Retrieved July 5, 2021, from https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "Wilimitis, D. (2019, February 21). The Kernel Trick in Support Vector Classification - Towards Data Science. Medium. https://towardsdatascience.com/the-kernel-trick-c98cdbcaeb3f\n",
    "\n",
    "Cross Validation and its types! | Data Science and Machine Learning. (n.d.). Kaggle. Retrieved July 5, 2021, from https://www.kaggle.com/general/204878\n",
    "\n",
    "Preparing the Dump Data of a TensorFlow Model - Atlas Intelligent Edge Solution V100R020C00 Development Auxiliary Tool Guide 01 - Huawei. (n.d.). Huawei. Retrieved July 5, 2021, from https://support.huawei.com/enterprise/en/doc/EDOC1100150947/86e94d01/preparing-the-dump-data-of-a-tensorflow-model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
